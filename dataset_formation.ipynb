{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine everything from Ergast DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load all CSV files\n",
    "results = pd.read_csv('./f1db_csv2024-2/results.csv')\n",
    "races = pd.read_csv('./f1db_csv2024-2/races.csv')\n",
    "drivers = pd.read_csv('./f1db_csv2024-2/drivers.csv')\n",
    "constructors = pd.read_csv('./f1db_csv2024-2/constructors.csv')\n",
    "laptimes = pd.read_csv('./f1db_csv2024-2/lap_times.csv')\n",
    "qualifying = pd.read_csv('./f1db_csv2024-2/qualifying.csv')\n",
    "pitstops = pd.read_csv('./f1db_csv2024-2/pit_stops.csv')\n",
    "driver_standings = pd.read_csv('./f1db_csv2024-2/driver_standings.csv')\n",
    "constructor_standings = pd.read_csv('./f1db_csv2024-2/constructor_standings.csv')\n",
    "\n",
    "pitstops = pitstops.drop(columns=['time'])\n",
    "driver_standings = driver_standings.drop(columns=['position', 'positionText'])\n",
    "constructor_standings = constructor_standings.drop(columns=['position', 'positionText'])\n",
    "\n",
    "\n",
    "# Merge results with races\n",
    "merged_df = pd.merge(results, races, on='raceId', how='left')\n",
    "\n",
    "# Merge with drivers\n",
    "merged_df = pd.merge(merged_df, drivers, on='driverId', how='left')\n",
    "\n",
    "\n",
    "merged_df = pd.merge(merged_df, constructors, on='constructorId', how='left')\n",
    "\n",
    "# Merge with laptimes\n",
    "merged_df = pd.merge(merged_df, laptimes, on=['raceId', 'driverId'], how='left')\n",
    "\n",
    "merged_df = pd.merge(merged_df, qualifying, on=['raceId', 'driverId'], how='left')\n",
    "\n",
    "merged_df = pd.merge(merged_df, driver_standings, on=['raceId', 'driverId'], how='left')\n",
    "\n",
    "print(merged_df.columns.tolist())\n",
    "merged_df = merged_df.rename(columns={'constructorId_x': 'constructorId'})\n",
    "merged_df = pd.merge(merged_df, constructor_standings, on=['raceId', 'constructorId'], how='left')\n",
    "\n",
    "merged_df = pd.merge(merged_df, pitstops, on=['raceId', 'driverId', 'lap'], how='left')\n",
    "\n",
    "\n",
    "merged_df = merged_df[merged_df['raceId'] >= 900]\n",
    "columns_to_remove = ['position_x', 'positionText', 'time_x', 'url_x', 'fp1_date', 'fp1_time', 'fp2_date', 'fp2_time', 'fp3_date', 'fp3_time', 'quali_date', 'quali_time', 'sprint_date', 'sprint_time', 'url_y', 'url']\n",
    "merged_df = merged_df.drop(columns=columns_to_remove)\n",
    "\n",
    "merged_df = merged_df.rename(columns={'time': 'laptime', 'points_y':'driverseasonpoints', 'points':'constructorseasonpoints', 'position':'qualiposition', 'position_y':'raceposition', 'wins_x':'driverwins', 'wins_y':'constructorwins'})\n",
    "\n",
    "\n",
    "merged_df['Driver_Season_Points'] = merged_df['driverseasonpoints'] - merged_df['points_x']\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "merged_df.to_csv('./f1db_csv2024-2/combined_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following cells must be done for each season separately "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more driver information to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "combinedresults = pd.read_csv('./f1db_csv2024-2/combined_results.csv')\n",
    "\n",
    "drivers_dict = {\n",
    "    1: {\"Abbreviation\": \"VER\", \"YOB\": 1997, \"Races_before\": 181, \"Races_won\": 54, \"Podiums\": 92},\n",
    "    11: {\"Abbreviation\": \"PER\", \"YOB\": 1990, \"Races_before\": 253, \"Races_won\": 6, \"Podiums\": 33},\n",
    "    44: {\"Abbreviation\": \"HAM\", \"YOB\": 1985, \"Races_before\": 328, \"Races_won\": 103, \"Podiums\": 196},\n",
    "    14: {\"Abbreviation\": \"ALO\", \"YOB\": 1981, \"Races_before\": 373, \"Races_won\": 32, \"Podiums\": 104},\n",
    "    16: {\"Abbreviation\": \"LEC\", \"YOB\": 1997, \"Races_before\": 122, \"Races_won\": 5, \"Podiums\": 28},\n",
    "     4: {\"Abbreviation\": \"NOR\", \"YOB\": 1999, \"Races_before\": 100, \"Races_won\": 0, \"Podiums\": 12},\n",
    "    55: {\"Abbreviation\": \"SAI\", \"YOB\": 1994, \"Races_before\": 182, \"Races_won\": 2, \"Podiums\": 17},\n",
    "    63: {\"Abbreviation\": \"RUS\", \"YOB\": 1998, \"Races_before\": 100, \"Races_won\": 1, \"Podiums\": 10},\n",
    "    81: {\"Abbreviation\": \"PIA\", \"YOB\": 2001, \"Races_before\": 18, \"Races_won\": 0, \"Podiums\": 2},\n",
    "    18: {\"Abbreviation\": \"STR\", \"YOB\": 1998, \"Races_before\": 140, \"Races_won\": 0, \"Podiums\": 3},\n",
    "    10: {\"Abbreviation\": \"GAS\", \"YOB\": 1996, \"Races_before\": 126, \"Races_won\": 1, \"Podiums\": 4},\n",
    "    31: {\"Abbreviation\": \"OCO\", \"YOB\": 1996, \"Races_before\": 126, \"Races_won\": 1, \"Podiums\": 3},\n",
    "    23: {\"Abbreviation\": \"ALB\", \"YOB\": 1996, \"Races_before\": 77, \"Races_won\": 0, \"Podiums\": 2},\n",
    "     2: {\"Abbreviation\":\"SAR\",\"YOB\" :2000,\"Races_before\" :22,\"Races_won\" :0,\"Podiums\" :0},\n",
    "    22: {\"Abbreviation\":\"TSU\",\"YOB\" :2000,\"Races_before\" :62,\"Races_won\" :0,\"Podiums\" :0},\n",
    "    87: {\"Abbreviation\":\"BEA\",\"YOB\" :2005,\"Races_before\" :0,\"Races_won\" :0,\"Podiums\" :0}, \n",
    "    43: {\"Abbreviation\":\"COL\",\"YOB\" :2003,\"Races_before\" :0,\"Races_won\" :0,\"Podiums\" :0}, \n",
    "     24:{\"Abbreviation\":\"ZHO\",\"YOB\" :1999,\"Races_before\" :40,\"Races_won\" :0,\"Podiums\" :0},\n",
    "     30:{\"Abbreviation\":\"LAW\",\"YOB\" :2002,\"Races_before\" :3,\"Races_won\" :0,\"Podiums\" :0},\n",
    "     77:{\"Abbreviation\":\"BOT\",\"YOB\" :1989,\"Races_before\" :218,\"Races_won\" :10,\"Podiums\" :67}, \n",
    "     3:{\"Abbreviation\":\"RIC\",\"YOB\" :1989,\"Races_before\" :232,\"Races_won\" :8,\"Podiums\" :32}, \n",
    "     20:{\"Abbreviation\":\"MAG\",\"YOB\" :1992,\"Races_before\" :160,\"Races_won\" :0,\"Podiums\" :1}\n",
    "}\n",
    "\n",
    "\n",
    "# Function to retrieve lap times for a given race\n",
    "def get_race_laptimes(season, round):\n",
    "\n",
    "    lap_times = []\n",
    "    for driver in drivers_dict:\n",
    "        laps = combinedresults[(combinedresults['year'] == season) & (combinedresults['round'] == round) & (combinedresults['number'] == driver)]\n",
    "        \n",
    "\n",
    "        if laps.empty:\n",
    "            print(\"Driver \"+str(driver)+\" is not in round \"+str(round))\n",
    "            continue\n",
    "        else:\n",
    "            laps.loc[:,'YOB'] = drivers_dict[driver]['YOB']\n",
    "            print(\"SUCCESS YOB\")\n",
    "            laps.loc[:,'Races_before'] = drivers_dict[driver]['Races_before']\n",
    "            laps.loc[:,'Races_won'] = drivers_dict[driver]['Races_won']\n",
    "            laps.loc[:,'Podiums'] = drivers_dict[driver]['Podiums']\n",
    "            \n",
    "            if(laps.loc[laps['number'] == driver]['points_x'].values[0]>=25):\n",
    "                drivers_dict[driver]['Races_won']+=1\n",
    "            \n",
    "            if(laps.loc[laps['number'] == driver]['points_x'].values[0]>=15):\n",
    "                drivers_dict[driver]['Podiums']+=1\n",
    "\n",
    "            drivers_dict[driver]['Races_before']+=1\n",
    "\n",
    "\n",
    "            lap_times.append(laps)\n",
    "\n",
    "    \n",
    "    print(\"Done with round \"+str(round))\n",
    "    return pd.concat(lap_times)\n",
    "\n",
    "# Can loop through seasons and rounds if information is available for all seasons, or else just do it one season at a time\n",
    "all_lap_times = []\n",
    "for season in range(2024, 2025):\n",
    "\n",
    "    for round in range(1, 25):  # Typically 22-24 rounds per season, adjust if necessary\n",
    "        try:\n",
    "            race_lap_times = get_race_laptimes(season, round)\n",
    "            all_lap_times.append(race_lap_times)\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving data for season {season}, round {round}: {e}\")\n",
    "\n",
    "\n",
    "# Combine all lap times into a single DataFrame\n",
    "all_lap_times_df = pd.concat(all_lap_times, ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "all_lap_times_df.to_csv('./f1db_csv2024-2/f1_lap_times_2024.csv', index=False)\n",
    "\n",
    "print(\"Lap times successfully retrieved and saved to 'f1_lap_times_2024.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding safety car info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_car_df = pd.read_csv('./f1db_csv2024/safety_cars.csv')\n",
    "laptimes = pd.read_csv('./f1db_csv2024-2/f1_lap_times_2024.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a new column `isSafetyCar` with 0\n",
    "laptimes['isSafetyCar'] = 0\n",
    "laptimes['isSafetyCarPrev'] = 0\n",
    "\n",
    "# Split the 'Race' column in safety_car_df into 'year' and 'name'\n",
    "safety_car_df['year'] = safety_car_df['Race'].apply(lambda x: int(x.split()[0]))\n",
    "safety_car_df['name'] = safety_car_df['Race'].apply(lambda x: ' '.join(x.split()[1:]))\n",
    "\n",
    "safety_car_df = safety_car_df[safety_car_df['year'] == 2024]\n",
    "\n",
    "# Iterate through each row in the safety car dataset\n",
    "for _, row in safety_car_df.iterrows():\n",
    "    race_year = row['year']\n",
    "    race_name = row['name']\n",
    "    deployed_lap = row['Deployed']\n",
    "    retreated_lap = row['Retreated']\n",
    "    \n",
    "    # Set `isSafetyCar` to 1 for laps between deployed and retreated in the same race\n",
    "    laptimes.loc[\n",
    "        (laptimes['year'] == race_year) & \n",
    "        (laptimes['name_x'] == race_name) & \n",
    "        (laptimes['lap'] >= deployed_lap) & \n",
    "        (laptimes['lap'] <= retreated_lap), 'isSafetyCar'\n",
    "    ] = 1\n",
    "\n",
    "    laptimes.loc[\n",
    "        (laptimes['year'] == race_year) & \n",
    "        (laptimes['name_x'] == race_name) & \n",
    "        ((laptimes['lap'] - 1)>= deployed_lap) & \n",
    "        ((laptimes['lap'] - 1) <= retreated_lap), 'isSafetyCarPrev'\n",
    "    ] = 1\n",
    "\n",
    "# Save the updated combined DataFrame to a new CSV file\n",
    "laptimes.to_csv('./f1db_csv2024-2/f1_lap_times_2024_safetycar.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting tyre compound information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastf1 as ff1\n",
    "\n",
    "# Enable caching for faster retrieval\n",
    "# ff1.Cache.enable_cache('cache')  # Create a cache folder\n",
    "\n",
    "# Initialize a list to store the data\n",
    "data = []\n",
    "\n",
    "# Loop through the seasons (2018 to 2023)\n",
    "for year in range(2024, 2025):\n",
    "    # Get the season schedule for the given year\n",
    "    schedule = ff1.get_event_schedule(year)\n",
    "    \n",
    "    # Loop through all the races (rounds) in the season\n",
    "    for round_num in schedule['RoundNumber']:\n",
    "        try:\n",
    "            # Load the session data for the race\n",
    "            session = ff1.get_session(year, round_num, 'R')  # 'R' stands for race session\n",
    "            session.load()  # Load the session data\n",
    "            \n",
    "            # Check if session.laps exists and is not empty\n",
    "            if session.laps.empty:\n",
    "                print(f\"No lap data for year {year}, round {round_num}\")\n",
    "                continue\n",
    "            \n",
    "            # Loop through all laps in the session\n",
    "            for _, lap in session.laps.iterrows():  # Use .iterrows() to iterate through DataFrame rows\n",
    "                # Ensure 'LapNumber' and 'Compound' exist in the data\n",
    "                if 'LapNumber' in lap and 'Compound' in lap:\n",
    "                    driver_lap = {\n",
    "                        'year': year,\n",
    "                        'round': round_num,\n",
    "                        'driver': lap['Driver'],\n",
    "                        'drivernumber': lap['DriverNumber'],\n",
    "                        'lap_number': lap['LapNumber'],\n",
    "                        'tyre_compound': lap['Compound']\n",
    "                    }\n",
    "                    data.append(driver_lap)\n",
    "                else:\n",
    "                    print(f\"Missing data for lap in year {year}, round {round_num}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load session for year {year}, round {round_num}: {e}\")\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('./f1db_csv2024-2/compounds_2024.csv', index=False)\n",
    "\n",
    "print(\"Data fetching and CSV export complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining safety car and tyre compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds = pd.read_csv('./f1db_csv2024-2/compounds_2024.csv')\n",
    "laptimes = pd.read_csv('./f1db_csv2024-2/f1_lap_times_2024_safetycar.csv')\n",
    "\n",
    "compounds = compounds.rename(columns={'lap_number':'lap', 'driver':'code'})\n",
    "\n",
    "merged_df = pd.merge(laptimes, compounds, on=['year', 'round', 'code', 'lap'], how='left')\n",
    "\n",
    "\n",
    "# Save the updated combined DataFrame to a new CSV file\n",
    "merged_df.to_csv('./f1db_csv2024-2/f1_lap_times_2024_raw_complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding tyre age info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./f1db_csv2024-2/f1_lap_times_2024_raw_complete.csv')\n",
    "\n",
    "# Sort the dataset by raceId, driverId, and lap number\n",
    "df = df.sort_values(by=['raceId', 'driverId', 'lap'])\n",
    "\n",
    "# Initialize a new column for tyre age\n",
    "df['tyre_age'] = 0\n",
    "\n",
    "# Loop through each driver and race to calculate tyre age\n",
    "for driver, driver_data in df.groupby(['raceId', 'driverId']):\n",
    "    tyre_age = 1  # Tyre age starts at 1 (since the first lap after a pit stop is lap 1 of tyre life)\n",
    "    \n",
    "    for index, row in driver_data.iterrows():\n",
    "        # If a pit stop occurs (row['stop'] > 0), set the next lap's tyre age to 1\n",
    "        if row['stop'] > 0:  # Pit stop detected\n",
    "            # Set the tyre age for the current lap\n",
    "            df.at[index, 'tyre_age'] = tyre_age\n",
    "\n",
    "            tyre_age = 1  # Reset tyre age to 0 for the current lap\n",
    "\n",
    "        else:\n",
    "            # Set the tyre age for the current lap\n",
    "            df.at[index, 'tyre_age'] = tyre_age\n",
    "        \n",
    "            # Increment the tyre age for the next lap\n",
    "            tyre_age += 1\n",
    "        \n",
    "        \n",
    "\n",
    "# Save the updated DataFrame with tyre age to a new CSV\n",
    "df.to_csv('./f1db_csv2024-2/f1_lap_times_2024_with_tyre_age.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding encodings for drivers, teams, and pitstops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./f1db_csv2024-2/f1_lap_times_2024_with_tyre_age.csv')\n",
    "\n",
    "# One-hot encode the 'tyre_compound' column\n",
    "df = pd.get_dummies(df, columns=['tyre_compound'], prefix='tyre', drop_first=False)\n",
    "\n",
    "\n",
    "# List of driver codes and corresponding column names\n",
    "drivers = [\n",
    "    ('VET', 'isVET'), ('ZHO', 'isZHO'), ('VER', 'isVER'), ('TSU', 'isTSU'), ('STR', 'isSTR'), \n",
    "    ('MSC', 'isMSC'), ('SAR', 'isSAR'), ('RIC', 'isRIC'), ('SAI', 'isSAI'), ('RUS', 'isRUS'), \n",
    "    ('PIA', 'isPIA'), ('PER', 'isPER'), ('OCO', 'isOCO'), ('NOR', 'isNOR'), ('MAG', 'isMAG'), \n",
    "    ('LEC', 'isLEC'), ('LAW', 'isLAW'), ('LAT', 'isLAT'), ('HUL', 'isHUL'), ('HAM', 'isHAM'), \n",
    "    ('GAS', 'isGAS'), ('DEV', 'isDEV'), ('BOT', 'isBOT'), ('BEA', 'isBEA'), ('ALO', 'isALO'), \n",
    "    ('ALB', 'isALB')\n",
    "]\n",
    "\n",
    "teams = {\n",
    "    'isRBR': ['red_bull'],\n",
    "    'isFER': ['ferrari'],\n",
    "    'isMER': ['mercedes'],\n",
    "    'isALP': ['alpine', 'renault'],\n",
    "    'isMCL': ['mclaren'],\n",
    "    'isALF': ['alfa', 'sauber'],\n",
    "    'isAST': ['aston_martin', 'racing_point', 'force_india'],\n",
    "    'isHAA': ['haas'],\n",
    "    'isATR': ['alphatauri', 'torro_rosso', 'rb'],\n",
    "    'isWIL': ['williams']\n",
    "}\n",
    "\n",
    "# Initialize all driver-related columns to 0\n",
    "for _, column_name in drivers:\n",
    "    df[column_name] = 0\n",
    "\n",
    "for column in teams.keys():\n",
    "    df[column] = 0\n",
    "\n",
    "\n",
    "\n",
    "df['isPitting'] = 0\n",
    "# Loop through each row and update the respective column based on the driver code\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    if row['stop'] > 0:  # Pit stop detected\n",
    "        # print(\"row: \"+str(index))\n",
    "        df.at[index, 'isPitting'] = 1\n",
    "    \n",
    "    driver_code = row['code']\n",
    "    \n",
    "    # Set the respective driver's column to 1 if there's a match\n",
    "    for code, column_name in drivers:\n",
    "        if driver_code == code:\n",
    "            df.at[index, column_name] = 1\n",
    "\n",
    "\n",
    "    constructor_ref = row['constructorRef'].lower()  # Make lowercase for case-insensitive matching\n",
    "    \n",
    "    for column, constructor_list in teams.items():\n",
    "        if any(constructor in constructor_ref for constructor in constructor_list):\n",
    "            df.at[index, column] = 1\n",
    "\n",
    "\n",
    "# Save the updated DataFrame to a new CSV\n",
    "df.to_csv('./f1db_csv2024-2/f1_lap_times_2024_encodings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
